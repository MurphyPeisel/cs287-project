{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e06a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# ML stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model as lm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bfd03d1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# what is inmigshare?\n",
    "data = pd.read_excel(\"data/Master file Jan23.xls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "86bf0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(data):\n",
    "    df = data\n",
    "    df = data[[\"StateCODE_orig\", \"StateABRV_orig\"]].drop_duplicates()\n",
    "    return zip(df.StateCODE_orig, df.StateABRV_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a1dfac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    temp_df = data\n",
    "    # aggregate % adults in original state\n",
    "    temp_df[\"Adults_orig\"] = temp_df.loc[:, [\"Adults_1925_orig\", \"Adults_2634_orig\", \"Adults_3554_orig\",\n",
    "                                            \"Adults_5564_orig\", \"Adults_65_orig\"]].sum(axis=1)\n",
    "    temp_df = temp_df.drop(columns = [\"Adults_1925_orig\", \"Adults_2634_orig\", \"Adults_3554_orig\",\n",
    "                                            \"Adults_5564_orig\", \"Adults_65_orig\"])\n",
    "    # aggregate % adults in destination state\n",
    "    temp_df[\"Adults_dest\"] = temp_df.loc[:, [\"Adults_1925_dest\", \"Adults_2634_dest\", \"Adults_3554_dest\",\n",
    "                                            \"Adults_5564_dest\", \"Adults_65_dest\"]].sum(axis=1)\n",
    "    temp_df = temp_df.drop(columns = [\"Adults_1925_dest\", \"Adults_2634_dest\", \"Adults_3554_dest\",\n",
    "                                            \"Adults_5564_dest\", \"Adults_65_dest\"])\n",
    "\n",
    "    # drop unneccesary columns\n",
    "    temp_df = temp_df.drop(columns = [\"Homic_death_orig\",\"Homic_death_dest\",\"Unemp_tot_orig\",\"Unemp_tot_dest\",\n",
    "                    \"StateNAME_orig\",\"StateNAME_dest\",\"outmigsharepercent\", \"inmigsharepercent\",\n",
    "                    \"PDSI_Rank_orig\",\"PDSI_Rank_dest\",\"PDSI_Anomaly_orig\", \"PDSI_Anomaly_dest\",\n",
    "                    \"Urban_rural_orig\",\"Urban_rural_dest\", 'MHV_Nom_orig','MGR_Nom_orig','AGR_Nom_orig',\n",
    "                    'Average_orig', 'MHV_Nom_dest','MGR_Nom_dest','AGR_Nom_dest','Average_dest',\n",
    "                    'Dem_Share_President_Two_orig', 'Rep_Share_President_Two_orig',\n",
    "                    'Dem_Share_President_Two_dest', 'Rep_Share_President_Two_dest',\n",
    "                    'Health_White_orig','Health_Black_orig','Health_Hispanic_orig','Health_Asian_orig',\n",
    "                    'Health_Alaska_orig','Other_orig', 'Health_White_dest','Health_Black_dest',\n",
    "                    'Health_Hispanic_dest','Health_Asian_dest','Health_Alaska_dest','Other_dest'])\n",
    "    \n",
    "    # rename poorly named columns\n",
    "    temp_df = temp_df.rename(columns = {\"Children_018_orig\": \"Children_orig\", \"Children_018_dest\": \"Children_dest\",\n",
    "                                       \"Econ_Free_Sum_dest\": \"Econ_Freedom_Score_dest\",\n",
    "                                        \"Econ_Free_Sum_orig\": \"Econ_Freedom_Score_orig\",\n",
    "                                       \"Reg_Pri_Par_orig\": \"Price_Parity_orig\", \"Reg_Pri_Par_orig\": \"Price_Parity_dest\",\n",
    "                                       \"cdd_orig\": \"cool_deg_day_orig\", \"cdd_dest\": \"cool_deg_day_dest\",\n",
    "                                       \"hdd_orig\": \"heat_deg_day_orig\", \"hdd_dest\": \"heat_deg_day_dest\"})\n",
    "    \n",
    "    # deal with nulls as we go?\n",
    "    temp_df[\"Children_orig\"] = temp_df[\"Children_orig\"].fillna(0)\n",
    "    temp_df[\"Children_dest\"] = temp_df[\"Children_dest\"].fillna(0)\n",
    "\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2cefd388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/simplest-way-of-creating-a-choropleth-map-by-u-s-states-in-python-f359ada7735e\n",
    "def make_choropleth(StateABRV):\n",
    "        temp_df = data[data[\"StateABRV_orig\"] == StateABRV]\n",
    "        temp_df = temp_df[[\"Year\", \"StateABRV_dest\", \"StateNAME_orig\", \"outmigshare\"]]\n",
    "        # log transform\n",
    "        temp_df[\"outmigshare\"] = temp_df[\"outmigshare\"].mask(temp_df[\"outmigshare\"] == 0, np.inf)\n",
    "        temp_df[\"Out-Migration Share (Log10 Scale)\"] = (np.log10(temp_df[\"outmigshare\"]))\n",
    "                \n",
    "        fig = px.choropleth(temp_df,\n",
    "                    locations='StateABRV_dest', \n",
    "                    locationmode=\"USA-states\", \n",
    "                    scope=\"usa\",\n",
    "                    color='Out-Migration Share (Log10 Scale)',\n",
    "                    color_continuous_scale=\"Viridis\",\n",
    "                    animation_frame = \"Year\",\n",
    "                    range_color = (-6, -1.5),\n",
    "                    title = temp_df[\"StateNAME_orig\"].unique()[0] + \" Out-Migration Share per Year (Log10 Scale)\")\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "87239e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_columns(data, *columns):\n",
    "    \"\"\"Select only columns passed as arguments.\"\"\"\n",
    "    return data.loc[:, columns]\n",
    "\n",
    "def process_data(data):\n",
    "    \"\"\"Process the data for a guided model.\"\"\"\n",
    "    \n",
    "    # Select Features\n",
    "    data = select_columns(data, \n",
    "                          'outmigshare', \n",
    "                          'Distance',\n",
    "                          'Year',\n",
    "                          'heat_deg_day_orig',\n",
    "                          'heat_deg_day_dest',\n",
    "                         )\n",
    "    \n",
    "\n",
    "    \n",
    "    # Return predictors and response variables separately\n",
    "    X = data.drop(['outmigshare'], axis = 1)\n",
    "    y = data.loc[:, 'outmigshare']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def test(data):\n",
    "    # Replace infinite updated data with nan\n",
    "    data.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    # Drop rows with NaN\n",
    "    data.fillna(0, inplace=True)\n",
    "    \"\"\"Creates a model to predict XXX with YYY\"\"\"\n",
    "    train, val = train_test_split(data, random_state=42, train_size=0.80)\n",
    "    X_train, y_train = process_data(train)\n",
    "    X_val, y_val = process_data(val)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "268b1b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'StateCODE_orig', 'StateCODE_dest', 'Mig_Estimate',\n",
       "       'outmigshare', 'inmigshare', 'Distance', 'StateABRV_orig',\n",
       "       'StateABRV_dest', 'Pop_orig', 'Children_orig', 'Health_Adults_orig',\n",
       "       'Homicide_Rate_orig', 'Kauf_rne_orig', 'Kauf_ose_orig', 'Kauf_sjc_orig',\n",
       "       'Kauf_ssr_orig', 'Kauf_zindex_orig', 'Unemp_rate_orig',\n",
       "       'dems_share_state_leg_orig', 'reps_share_state_leg_orig',\n",
       "       'dems_control_state_leg_orig', 'reps_control_state_leg_orig',\n",
       "       'Dem_Share_Prez_orig', 'Rep_Share_Prez_orig',\n",
       "       'Median_House_Value_adj_orig', 'Median_Gross_Rent_adj_orig',\n",
       "       'Average_Gross_Rent_adj_orig', 'GoodDays_orig', 'Inc_Corp_Tax_orig',\n",
       "       'StateGDP_Millions_orig', 'PDSI_Value_orig', 'Price_Parity_dest',\n",
       "       'Econ_Freedom_Score_orig', 'Homeown_Perc_orig', 'Median_HHI_orig',\n",
       "       'Median_HHI_adj_orig', 'Coll_Educ_orig', 'heat_deg_day_orig',\n",
       "       'cool_deg_day_orig', 'Pop_dest', 'Children_dest', 'Health_Adults_dest',\n",
       "       'Homicide_Rate_dest', 'Kauf_rne_dest', 'Kauf_ose_dest', 'Kauf_sjc_dest',\n",
       "       'Kauf_ssr_dest', 'Kauf_zindex_dest', 'Unemp_rate_dest',\n",
       "       'dems_share_state_leg_dest', 'reps_share_state_leg_dest',\n",
       "       'dems_control_state_leg_dest', 'reps_control_state_leg_dest',\n",
       "       'Dem_Share_Prez_dest', 'Rep_Share_Prez_dest',\n",
       "       'Median_House_Value_adj_dest', 'Median_Gross_Rent_adj_dest',\n",
       "       'Average_Gross_Rent_adj_dest', 'GoodDays_dest', 'Inc_Corp_Tax_dest',\n",
       "       'StateGDP_Millions_dest', 'PDSI_Value_dest', 'Reg_Pri_Par_dest',\n",
       "       'Econ_Freedom_Score_dest', 'Homeown_Perc_dest', 'Median_HHI_dest',\n",
       "       'Median_HHI_adj_dest', 'Coll_Educ_dest', 'heat_deg_day_dest',\n",
       "       'cool_deg_day_dest', 'Adults_orig', 'Adults_dest'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = clean(data)\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d5a97a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33320,)\n",
      "(33320, 4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [162]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 16\u001b[0m training_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, training_accuracy)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:706\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[0;32m    705\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m--> 706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mr2_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:789\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mr2_score\u001b[39m(y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;124;03m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;124;03m    -3.0\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    792\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:95\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m    the dtype argument passed to check_array.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m---> 95\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    797\u001b[0m         )\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 800\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    108\u001b[0m         allow_nan\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m    112\u001b[0m     ):\n\u001b[0;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    117\u001b[0m             )\n\u001b[0;32m    118\u001b[0m         )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Attempt at modeling stuff\n",
    "\n",
    "X_train, y_train, X_val, y_val = test(cleaned_data)\n",
    "\n",
    "\n",
    "linear_model = lm.LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "# print(X_train)\n",
    "# print(\"\")\n",
    "# print(y_train)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "training_accuracy = linear_model.score(X_train, Y_train)\n",
    "print(\"Training Accuracy: \", training_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e86871a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4b418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76517a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
